import pandas as pdimport numpy as npimport matplotlib.pyplot as plt# Importing the datasetdataset = pd.read_csv("Mall_Customers.csv")x = dataset.iloc[:, [3,4]].values# At this point we don't have a dependent variable. I am trying to create one. # So I don't need a y dependent variable y. # Splitting the dataset into training set and test set# from sklearn.model_selection import train_test_split# x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)# Feature Scalling# from sklearn.preprocessing import StandardScaler# sc = StandardScaler()# x_train = sc.fit_transform(x_train)# x_test = sc.fit(x_test)# Fitting Classifier to training set# Using the elbow method to find the optimal number of clustersfrom sklearn.cluster import KMeanswcss = []for c in range(1,11):    kmeans = KMeans(n_clusters=c, init='k-means++', random_state=42)    kmeans.fit(x)    wcss.append(kmeans.inertia_)plt.plot(range(1,11), wcss)plt.title('The Elbow Method')plt.xlabel('Number of clusters')plt.ylabel('WCSS')plt.show()kmeans = KMeans(n_clusters=5, init='k-means++', random_state=42)# fit_predict method returns the dependent variabley_kmeans = kmeans.fit_predict(x)# Visualizing the clustersplt.scatter(x[y_kmeans == 0 ,0], x[y_kmeans == 0, 1], s=100, c='red', label='Cluster 1')plt.scatter(x[y_kmeans == 1 ,0], x[y_kmeans == 1, 1], s=100, c='blue', label='Cluster 2')plt.scatter(x[y_kmeans == 2 ,0], x[y_kmeans == 2, 1], s=100, c='green', label='Cluster 3')plt.scatter(x[y_kmeans == 3 ,0], x[y_kmeans == 3, 1], s=100, c='cyan', label='Cluster 4')plt.scatter(x[y_kmeans == 4 ,0], x[y_kmeans == 4, 1], s=100, c='magenta', label='Cluster 5')plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s=300, c='yellow', label='Centroids')plt.title('Clusters of customers')plt.xlabel('Annual Income (k$)')plt.ylabel('SPending Score (1-100)')plt.legend()plt.show()