import pandas as pdimport matplotlib.pyplot as pltimport numpy as np# Importing the datasetdataset = pd.read_csv("Mall_Customers.csv")x = dataset.iloc[:, [3,4]].values# At this point we don't have a dependent variable. I am trying to create one. # So I don't need a y dependent variable y. # Splitting the dataset into training set and test set# from sklearn.model_selection import train_test_split# x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)# Feature Scalling# from sklearn.preprocessing import StandardScaler# sc = StandardScaler()# x_train = sc.fit_transform(x_train)# x_test = sc.fit(x_test)# Fitting Classifier to training set# using the dendrogram to finr the optimal number of clustersimport scipy.cluster.hierarchy as schdendrogram = sch.dendrogram(sch.linkage(x, method='ward'))plt.title('Dendrogram')plt.xlabel('Customers') # observation pointplt.ylabel('Euclidean Distances')plt.show()# fit_predict method returns the dependent variablefrom sklearn.cluster import AgglomerativeClustering# ward is the min variance methodhc = AgglomerativeClustering(n_clusters=5, affinity='euclidean', linkage='ward')y_hc = hc.fit_predict(x) # returns clusters of the dataset as well# Visualizing the clustersplt.scatter(x[y_hc == 0 ,0], x[y_hc == 0, 1], s=100, c='red', label='Cluster 1')plt.scatter(x[y_hc == 1 ,0], x[y_hc == 1, 1], s=100, c='blue', label='Cluster 2')plt.scatter(x[y_hc == 2 ,0], x[y_hc == 2, 1], s=100, c='green', label='Cluster 3')plt.scatter(x[y_hc == 3 ,0], x[y_hc == 3, 1], s=100, c='cyan', label='Cluster 4')plt.scatter(x[y_hc == 4 ,0], x[y_hc == 4, 1], s=100, c='magenta', label='Cluster 5')plt.title('Clusters of customers')plt.xlabel('Annual Income (k$)')plt.ylabel('Spending Score (1-100)')plt.legend()plt.show()